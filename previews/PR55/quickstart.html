<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Quickstart · ArviZ.jl</title><link rel="canonical" href="stable/quickstart.html"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/favicon.ico" rel="icon" type="image/x-icon"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="index.html"><img class="docs-light-only" src="assets/logo.png" alt="ArviZ.jl logo"/><img class="docs-dark-only" src="assets/logo-dark.png" alt="ArviZ.jl logo"/></a><form class="docs-search" action="search.html"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="index.html">Home</a></li><li class="is-active"><a class="tocitem" href="quickstart.html">Quickstart</a><ul class="internal"><li><a class="tocitem" href="#Get-started-with-plotting-1"><span>Get started with plotting</span></a></li><li><a class="tocitem" href="#Plotting-with-MCMCChains.jl&#39;s-Chains-objects-produced-by-Turing.jl-1"><span>Plotting with MCMCChains.jl&#39;s <code>Chains</code> objects produced by Turing.jl</span></a></li><li><a class="tocitem" href="#Plotting-with-CmdStan.jl-outputs-1"><span>Plotting with CmdStan.jl outputs</span></a></li><li><a class="tocitem" href="#Plotting-with-Soss.jl-outputs-1"><span>Plotting with Soss.jl outputs</span></a></li><li><a class="tocitem" href="#Environment-1"><span>Environment</span></a></li></ul></li><li><a class="tocitem" href="api.html">API</a></li><li><a class="tocitem" href="reference.html">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href="quickstart.html">Quickstart</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href="quickstart.html">Quickstart</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/arviz-devs/ArviZ.jl/blob/master/docs/src/quickstart.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="quickstart-1"><a class="docs-heading-anchor" href="#quickstart-1">ArviZ.jl Quickstart</a><a class="docs-heading-anchor-permalink" href="#quickstart-1" title="Permalink"></a></h1><p><em>This quickstart is adapted from <a href="https://arviz-devs.github.io/arviz/notebooks/Introduction.html">ArviZ&#39;s Quickstart</a>.</em></p><pre><code class="language-julia">using ArviZ

# ArviZ ships with style sheets!
ArviZ.use_style(&quot;arviz-darkgrid&quot;)</code></pre><h2 id="Get-started-with-plotting-1"><a class="docs-heading-anchor" href="#Get-started-with-plotting-1">Get started with plotting</a><a class="docs-heading-anchor-permalink" href="#Get-started-with-plotting-1" title="Permalink"></a></h2><p>ArviZ.jl is designed to be used with libraries like <a href="https://github.com/StanJulia/CmdStan.jl">CmdStan</a>, <a href="https://turing.ml">Turing.jl</a>, and <a href="https://github.com/cscherrer/Soss.jl">Soss.jl</a> but works fine with raw arrays.</p><pre><code class="language-julia">using Random

rng = Random.MersenneTwister(42)
plot_posterior(randn(rng, 100_000));</code></pre><p><img src="quick_postarray.svg" alt/></p><p>Plotting a dictionary of arrays, ArviZ.jl will interpret each key as the name of a different random variable. Each row of an array is treated as an independent series of draws from the variable, called a <em>chain</em>. Below, we have 10 chains of 50 draws each for four different distributions.</p><pre><code class="language-julia">using Distributions

s = (10, 50)
plot_forest(Dict(
    &quot;normal&quot; =&gt; randn(rng, s),
    &quot;gumbel&quot; =&gt; rand(rng, Gumbel(), s),
    &quot;student t&quot; =&gt; rand(rng, TDist(6), s),
    &quot;exponential&quot; =&gt; rand(rng, Exponential(), s)
));</code></pre><p><img src="quick_forestdists.svg" alt/></p><h2 id="Plotting-with-MCMCChains.jl&#39;s-Chains-objects-produced-by-Turing.jl-1"><a class="docs-heading-anchor" href="#Plotting-with-MCMCChains.jl&#39;s-Chains-objects-produced-by-Turing.jl-1">Plotting with MCMCChains.jl&#39;s <code>Chains</code> objects produced by Turing.jl</a><a class="docs-heading-anchor-permalink" href="#Plotting-with-MCMCChains.jl&#39;s-Chains-objects-produced-by-Turing.jl-1" title="Permalink"></a></h2><p>ArviZ is designed to work well with high dimensional, labelled data. Consider the <a href="https://statmodeling.stat.columbia.edu/2014/01/21/everything-need-know-bayesian-statistics-learned-eight-schools/">eight schools model</a>, which roughly tries to measure the effectiveness of SAT classes at eight different schools. To show off ArviZ&#39;s labelling, I give the schools the names of <a href="https://en.wikipedia.org/wiki/Eight_Schools_Association">a different eight schools</a>.</p><p>This model is small enough to write down, is hierarchical, and uses labelling. Additionally, a centered parameterization causes <a href="https://mc-stan.org/users/documentation/case-studies/divergences_and_bias.html">divergences</a> (which are interesting for illustration).</p><p>First we create our data and set some sampling parameters.</p><pre><code class="language-julia">J = 8
y = [28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0]
σ = [15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0]
schools = [
    &quot;Choate&quot;,
    &quot;Deerfield&quot;,
    &quot;Phillips Andover&quot;,
    &quot;Phillips Exeter&quot;,
    &quot;Hotchkiss&quot;,
    &quot;Lawrenceville&quot;,
    &quot;St. Paul&#39;s&quot;,
    &quot;Mt. Hermon&quot;
];

nwarmup, nsamples, nchains = 1000, 1000, 4;</code></pre><p>Now we write and run the model using Turing:</p><pre><code class="language-julia">using Turing

Turing.@model turing_model(
    J,
    y,
    σ,
    ::Type{TV} = Vector{Float64},
) where {TV} = begin
    μ ~ Normal(0, 5)
    τ ~ truncated(Cauchy(0, 5), 0, Inf)
    θ = TV(undef, J)
    θ .~ Normal(μ, τ)
    y ~ MvNormal(θ, σ)
end

param_mod = turing_model(J, y, σ)
sampler = NUTS(nwarmup, 0.8)

turing_chns = psample(
    param_mod,
    sampler,
    nwarmup + nsamples,
    nchains;
    progress = true,
);</code></pre><p>Most ArviZ functions work fine with <code>Chains</code> objects from Turing:</p><pre><code class="language-">plot_autocorr(convert_to_inference_data(turing_chns); var_names = [&quot;μ&quot;, &quot;τ&quot;]);
savefig(&quot;quick_turingautocorr.svg&quot;); nothing # hide</code></pre><p><img src="quick_turingautocorr.svg" alt/></p><h3 id="Convert-to-InferenceData-1"><a class="docs-heading-anchor" href="#Convert-to-InferenceData-1">Convert to <code>InferenceData</code></a><a class="docs-heading-anchor-permalink" href="#Convert-to-InferenceData-1" title="Permalink"></a></h3><p>For much more powerful querying, analysis and plotting, we can use built-in ArviZ utilities to convert <code>Chains</code> objects to xarray datasets. Note we are also giving some information about labelling.</p><p>ArviZ is built to work with <a href="reference.html#ArviZ.InferenceData"><code>InferenceData</code></a> (a netcdf datastore that loads data into <code>xarray</code> datasets), and the more <em>groups</em> it has access to, the more powerful analyses it can perform.</p><pre><code class="language-">idata = from_mcmcchains(
    turing_chns,
#     prior = prior, # hide
#     posterior_predictive = posterior_predictive, # hide
    coords = Dict(&quot;school&quot; =&gt; schools),
    dims = Dict(
        &quot;y&quot; =&gt; [&quot;school&quot;],
        &quot;σ&quot; =&gt; [&quot;school&quot;],
        &quot;θ&quot; =&gt; [&quot;school&quot;],
    ),
    library = &quot;Turing&quot;,
)</code></pre><p>Each group is an <a href="reference.html#ArviZ.Dataset"><code>ArviZ.Dataset</code></a> (a thinly wrapped <code>xarray.Dataset</code>). We can view a summary of the dataset.</p><pre><code class="language-">idata.posterior</code></pre><p>Here is a plot of the trace. Note the intelligent labels.</p><pre><code class="language-">plot_trace(idata);
savefig(&quot;quick_turingtrace.png&quot;); nothing # hide</code></pre><p><img src="quick_turingtrace.png" alt/></p><p>We can also generate summary stats</p><pre><code class="language-">summarystats(idata)</code></pre><p>and examine the energy distribution of the Hamiltonian sampler</p><pre><code class="language-">plot_energy(idata);
savefig(&quot;quick_turingenergy.svg&quot;); nothing # hide</code></pre><p><img src="quick_turingenergy.svg" alt/></p><h2 id="Plotting-with-CmdStan.jl-outputs-1"><a class="docs-heading-anchor" href="#Plotting-with-CmdStan.jl-outputs-1">Plotting with CmdStan.jl outputs</a><a class="docs-heading-anchor-permalink" href="#Plotting-with-CmdStan.jl-outputs-1" title="Permalink"></a></h2><p>CmdStan.jl and StanSample.jl also default to producing <code>Chains</code> outputs, and we can easily plot these chains.</p><p>Here is the same centered eight schools model:</p><pre><code class="language-julia">using CmdStan, MCMCChains

schools_code = &quot;&quot;&quot;
data {
  int&lt;lower=0&gt; J;
  real y[J];
  real&lt;lower=0&gt; sigma[J];
}

parameters {
  real mu;
  real&lt;lower=0&gt; tau;
  real theta[J];
}

model {
  mu ~ normal(0, 5);
  tau ~ cauchy(0, 5);
  theta ~ normal(mu, tau);
  y ~ normal(theta, sigma);
}

generated quantities {
    vector[J] log_lik;
    vector[J] y_hat;
    for (j in 1:J) {
        log_lik[j] = normal_lpdf(y[j] | theta[j], sigma[j]);
        y_hat[j] = normal_rng(theta[j], sigma[j]);
    }
}
&quot;&quot;&quot;

schools_dat = Dict(&quot;J&quot; =&gt; J, &quot;y&quot; =&gt; y, &quot;sigma&quot; =&gt; σ)
stan_model = Stanmodel(
    model = schools_code,
    name = &quot;schools&quot;,
    nchains = nchains,
    num_warmup = nwarmup,
    num_samples = nsamples,
    output_format = :mcmcchains,
    random = CmdStan.Random(8675309),
)
_, stan_chns, _ = stan(stan_model, schools_dat, summary = false);</code></pre><pre><code class="language-none">
File /home/vsts/work/1/s/docs/build/tmp/schools.stan will be updated.</code></pre><pre><code class="language-julia">plot_density(convert_to_inference_data(stan_chns); var_names=[&quot;mu&quot;, &quot;tau&quot;]);</code></pre><p><img src="quick_cmdstandensity.svg" alt/></p><p>Again, converting to <code>InferenceData</code>, we can get much richer labelling and mixing of data. Note that we&#39;re using the same <a href="reference.html#ArviZ.from_cmdstan-Tuple"><code>from_cmdstan</code></a> function used by ArviZ to process cmdstan output files, but through the power of dispatch in Julia, if we pass a <code>Chains</code> object, it instead uses ArviZ.jl&#39;s overloads, which forward to <a href="reference.html#ArviZ.from_mcmcchains-Tuple{Any,Any,Any}"><code>from_mcmcchains</code></a>.</p><pre><code class="language-julia">idata = from_cmdstan(
    stan_chns;
    posterior_predictive = &quot;y_hat&quot;,
    observed_data = Dict(&quot;y&quot; =&gt; schools_dat[&quot;y&quot;]),
    log_likelihood = &quot;log_lik&quot;,
    coords = Dict(&quot;school&quot; =&gt; schools),
    dims = Dict(
        &quot;y&quot; =&gt; [&quot;school&quot;],
        &quot;sigma&quot; =&gt; [&quot;school&quot;],
        &quot;theta&quot; =&gt; [&quot;school&quot;],
        &quot;log_lik&quot; =&gt; [&quot;school&quot;],
        &quot;y_hat&quot; =&gt; [&quot;school&quot;],
    ),
)</code></pre><pre><code class="language-none">InferenceData with groups:
	&gt; posterior
	&gt; posterior_predictive
	&gt; sample_stats
	&gt; observed_data</code></pre><p>Here is a plot showing where the Hamiltonian sampler had divergences:</p><pre><code class="language-julia">plot_pair(
    idata;
    coords = Dict(&quot;school&quot; =&gt; [&quot;Choate&quot;, &quot;Deerfield&quot;, &quot;Phillips Andover&quot;]),
    divergences = true,
);</code></pre><p><img src="quick_cmdstanpair.png" alt/></p><h2 id="Plotting-with-Soss.jl-outputs-1"><a class="docs-heading-anchor" href="#Plotting-with-Soss.jl-outputs-1">Plotting with Soss.jl outputs</a><a class="docs-heading-anchor-permalink" href="#Plotting-with-Soss.jl-outputs-1" title="Permalink"></a></h2><p>With Soss, we can define our model for the posterior and easily use it to draw samples from the prior, prior predictive, posterior, and posterior predictive distributions.</p><p>First we define our model:</p><pre><code class="language-julia">using Soss, NamedTupleTools

mod = Soss.@model (J, σ) begin
    μ ~ Normal(0, 5)
    τ ~ HalfCauchy(5)
    θ ~ Normal(μ, τ) |&gt; iid(J)
    y ~ For(1:J) do j
        Normal(θ[j], σ[j])
    end
end

constant_data = (J = J, σ = σ)
param_mod = mod(; constant_data...)</code></pre><pre><code class="language-none">Joint Distribution
    Bound arguments: [J, σ]
    Variables: [τ, μ, θ, y]

@model (J, σ) begin
        τ ~ HalfCauchy(5)
        μ ~ Normal(0, 5)
        θ ~ Normal(μ, τ) |&gt; iid(J)
        y ~ For(1:J) do j
                Normal(θ[j], σ[j])
            end
    end
</code></pre><p>Then we draw from the prior and prior predictive distributions.</p><pre><code class="language-julia">Random.seed!(5298)
prior_prior_pred = map(1:nchains*nsamples) do _
    draw = rand(param_mod)
    return delete(draw, keys(constant_data))
end

prior = map(draw -&gt; delete(draw, :y), prior_prior_pred)
prior_pred = map(draw -&gt; delete(draw, (:μ, :τ, :θ)), prior_prior_pred);</code></pre><p>Next, we draw from the posterior using <a href="https://github.com/tpapp/DynamicHMC.jl">DynamicHMC.jl</a>.</p><pre><code class="language-julia">post = map(1:nchains) do _
    dynamicHMC(param_mod, (y = y,), nsamples)
end;</code></pre><p>Finally, we use the posterior samples to draw from the posterior predictive distribution.</p><pre><code class="language-julia">pred = predictive(mod, :μ, :τ, :θ)
post_pred = map(post) do post_draws
    map(post_draws) do post_draw
        pred_draw = rand(pred(post_draw)(constant_data))
        return delete(pred_draw, keys(constant_data))
    end
end;</code></pre><p>Each Soss draw is a <code>NamedTuple</code>. Now we combine all of the samples to an <code>InferenceData</code>:</p><pre><code class="language-julia">idata = from_namedtuple(
    post;
    posterior_predictive = post_pred,
    prior = [prior],
    prior_predictive = [prior_pred],
    observed_data = Dict(&quot;y&quot; =&gt; y),
    constant_data = constant_data,
    coords = Dict(&quot;school&quot; =&gt; schools),
    dims = Dict(
        &quot;y&quot; =&gt; [&quot;school&quot;],
        &quot;σ&quot; =&gt; [&quot;school&quot;],
        &quot;θ&quot; =&gt; [&quot;school&quot;],
    ),
    library = Soss,
)</code></pre><pre><code class="language-none">InferenceData with groups:
	&gt; posterior
	&gt; posterior_predictive
	&gt; prior
	&gt; prior_predictive
	&gt; observed_data
	&gt; constant_data</code></pre><p>We can compare the prior and posterior predictive distributions:</p><pre><code class="language-julia">plot_density(
    [idata.posterior_predictive, idata.prior_predictive];
    data_labels = [&quot;Post-pred&quot;, &quot;Prior-pred&quot;],
    var_names = [&quot;y&quot;],
)</code></pre><p><img src="quick_sosspred.png" alt/></p><h2 id="Environment-1"><a class="docs-heading-anchor" href="#Environment-1">Environment</a><a class="docs-heading-anchor-permalink" href="#Environment-1" title="Permalink"></a></h2><pre><code class="language-julia">using Pkg
Pkg.status()</code></pre><pre><code class="language-none">    Status `~/work/1/s/docs/Project.toml`
  [131c737c] ArviZ v0.3.2 [`~/work/1/s`]
  [593b3428] CmdStan v6.0.2
  [31c24e10] Distributions v0.22.4
  [e30172f5] Documenter v0.24.5
  [c7f686f2] MCMCChains v3.0.0
  [d9ec5142] NamedTupleTools v0.12.1
  [8ce77f84] Soss v0.10.0 #master (https://github.com/cscherrer/Soss.jl.git)</code></pre><pre><code class="language-julia">using InteractiveUtils
versioninfo()</code></pre><pre><code class="language-none">Julia Version 1.3.1
Commit 2d5741174c (2019-12-30 21:36 UTC)
Platform Info:
  OS: Linux (x86_64-pc-linux-gnu)
  CPU: Intel(R) Xeon(R) Platinum 8171M CPU @ 2.60GHz
  WORD_SIZE: 64
  LIBM: libopenlibm
  LLVM: libLLVM-6.0.1 (ORCJIT, skylake)
Environment:
  JULIA_VERSION = 1.3
  JULIA_CMDSTAN_HOME = /home/vsts/work/_temp/.cmdstan//cmdstan-2.22.1/</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="index.html">« Home</a><a class="docs-footer-nextpage" href="api.html">API »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Tuesday 25 February 2020 08:03">Tuesday 25 February 2020</span>. Using Julia version 1.3.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
